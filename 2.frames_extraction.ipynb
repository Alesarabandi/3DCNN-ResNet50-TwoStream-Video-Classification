{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447601a6",
   "metadata": {},
   "source": [
    "# HMDB51 Frame Extraction & Validation Notebook\n",
    "\n",
    "This notebook is all about to **extracting uniform video frames** from the HMDB51 dataset and ensuring data quality before training any deep learning model.\n",
    "\n",
    "## Here's why I extract frames:\n",
    "\n",
    "### 1. Deep Learning Models Can‚Äôt Read Video Files Directly\n",
    "- PyTorch models (like 3D CNNs) need **tensors**, not media files.\n",
    "- You can‚Äôt just slap an `.avi` into `model(input)` and expect magic.\n",
    "- So, we break videos down into their individual frames (images).\n",
    "\n",
    "### 2. Tensors Must Have Specific Shapes\n",
    "- For 3D CNNs, each input clip should be a 5D tensor like this: [Batch, Channels, Time, Height, Width]\n",
    "- Extracting frames lets us manually build this structure from clips ‚Äî clean and precise.\n",
    "\n",
    "### 3. Preprocessing & Augmentation Becomes Easier\n",
    "- Once we‚Äôve got frames, we can apply all sorts of data augmentation:\n",
    "- Random crop, flip, color jitter, temporal jitter, etc.\n",
    "- This makes my model more robust.\n",
    "\n",
    "### 4. Speed & Flexibility During Training\n",
    "- Loading frames is way faster than decoding videos on the fly (anyway I will try to do it on fly in one of the model just to see how it works).\n",
    "- Especially in environments like **Google Colab**, where real-time video decoding can get proper laggy and consuming my very limited GPU time.\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "| Step   | Description                                                                 |\n",
    "|--------|-----------------------------------------------------------------------------|\n",
    "| Step 1 | Extract **16 evenly spaced frames** per video from the dataset      |\n",
    "| Step 2 | Clean and **skip corrupted or too-short videos**                            |\n",
    "| Step 3 | Validate that every video folder contains **16 readable images**     |\n",
    "| Step 4 | Detect any frames with **strange dimensions** (e.g., blank or undersized)   |\n",
    "| Step 5 | Report all issues for further cleaning or reprocessing                      |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91a58a",
   "metadata": {},
   "source": [
    "## Extract 16 Valid Frames from Each Video\n",
    "\n",
    "This chunk is the **core frame extraction logic**. It performs the following steps:\n",
    "\n",
    "1. **Reads each video** using OpenCV.\n",
    "2. **Filters out unreadable videos** and skips those with fewer than 16 valid frames.\n",
    "3. **Uniformly samples exactly 16 frames** using `np.linspace` to spread them across the full duration.\n",
    "4. **Saves frames** into a dedicated folder for each video using the format `0000.jpg`, `0001.jpg`, etc.\n",
    "5. **Iterates through each class** folder and video file within the dataset.\n",
    "\n",
    "If the video is too short or cannot be read, it's safely skipped with a warning message (luckily we didn't face this issue).\n",
    "\n",
    "**Configurable parameter:**\n",
    "- `target_num_frames`: how many frames to extract (set to 16).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a6852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìÇ Processing classes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52/52 [05:08<00:00,  5.94s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Config\n",
    "input_video_dir = \"/Users/alesarabandi/Downloads/DEEPLEARING/videos\"\n",
    "output_frame_dir = \"/Users/alesarabandi/Downloads/DEEPLEARING/frames\"\n",
    "target_num_frames = 16\n",
    "min_required_frames = 16\n",
    "\n",
    "def extract_exact_16_valid_frames(video_path, output_dir, target_num_frames=16):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open {video_path}\")\n",
    "        return\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    total_valid = len(frames)\n",
    "    if total_valid < target_num_frames:\n",
    "        print(f\"Skipping {video_path.name} (only {total_valid} valid frames)\")\n",
    "        return\n",
    "\n",
    "    # uniformly sample 16 indices from the valid ones\n",
    "    indices = np.linspace(0, total_valid - 1, target_num_frames, dtype=int)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        frame = frames[idx]\n",
    "        out_path = os.path.join(output_dir, f\"{i:04d}.jpg\")\n",
    "        cv2.imwrite(out_path, frame)\n",
    "\n",
    "    if len(indices) != target_num_frames:\n",
    "        print(f\"{video_path.name}: Extracted {len(indices)} frames instead of {target_num_frames}\")\n",
    "\n",
    "# wwalk through class folders and process videos \n",
    "input_dir = Path(input_video_dir)\n",
    "output_dir = Path(output_frame_dir)\n",
    "\n",
    "for class_dir in tqdm(sorted(input_dir.iterdir()), desc=\"Processing classes\"):\n",
    "    if class_dir.is_dir():\n",
    "        for video_path in sorted(class_dir.glob(\"*.avi\")):\n",
    "            video_name = video_path.stem\n",
    "            output_subdir = output_dir / class_dir.name / video_name\n",
    "            extract_exact_16_valid_frames(video_path, output_subdir, target_num_frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f8d18",
   "metadata": {},
   "source": [
    "## Validate Frame Count Per Video\n",
    "\n",
    "This chunk performs **data integrity checks** on the extracted frames to ensure consistency across the dataset.\n",
    "\n",
    "### What it does:\n",
    "- Walks through each class and each video folder in the `frames` directory.\n",
    "- Counts how many `.jpg` frame files exist per video.\n",
    "- Increments a counter if a video has exactly **16 frames**.\n",
    "- Flags and stores the path if a video has **fewer or more** than 16 frames.\n",
    "\n",
    "### Output:\n",
    "- Summary of how many videos are correct vs problematic.\n",
    "- A list of video directories with issues and how many frames they contain.\n",
    "\n",
    "> **Why this matters:** My models expect a fixed input shape ensuring that every video yields exactly 16 frames is **crucial for consistent training and inference**, I know I did not get the warning when about corrupted video on the chunk that I was trying to extract the frames but here just wanna double check.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49090d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Videos with exactly 16 frames: 6766/6766\n",
      "üéâ All videos have exactly 16 frames.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "frame_root_dir = Path(\"/Users/alesarabandi/Downloads/DEEPLEARING/frames\")\n",
    "\n",
    "\n",
    "total_videos = 0\n",
    "valid_16 = 0\n",
    "problems = []\n",
    "\n",
    "for class_dir in frame_root_dir.iterdir():\n",
    "    if class_dir.is_dir():\n",
    "        for video_dir in class_dir.iterdir():\n",
    "            if video_dir.is_dir():\n",
    "                frame_count = len([f for f in video_dir.glob(\"*.jpg\")])\n",
    "                total_videos += 1\n",
    "                if frame_count == 16:\n",
    "                    valid_16 += 1\n",
    "                else:\n",
    "                    problems.append((video_dir, frame_count))\n",
    "\n",
    "print(f\"‚úÖ Videos with exactly 16 frames: {valid_16}/{total_videos}\")\n",
    "if problems:\n",
    "    print(f\" Problems found in {len(problems)} videos:\")\n",
    "    for path, count in problems:\n",
    "        print(f\"{path}: {count} frames\")\n",
    "else:\n",
    "    print(\"üéâ All videos have exactly 16 frames.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315607b",
   "metadata": {},
   "source": [
    "## Check for Corrupted or Unreadable Frame Files\n",
    "\n",
    "This chunk ensures **every extracted frame image is valid and usable** for training.\n",
    "\n",
    "### What it does:\n",
    "- Iterates through all `.jpg` frame files inside the extracted video folders.\n",
    "- Uses `cv2.imread()` to try reading each image.\n",
    "- Flags the frame if:\n",
    "  - It **fails to load** (`None`), or\n",
    "  - The image has **zero size** (`img.size == 0`).\n",
    "\n",
    "### Output:\n",
    "- A list of all corrupted or unreadable frames, if any exist.\n",
    "- A success message if all frames are valid and properly loaded.\n",
    "\n",
    "> **Why this matters:** Even if a video has 16 frames, corrupted or unreadable images can silently break training or evaluation. This check ensures **data reliability** before moving forward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All frame images are readable and non-empty.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "corrupted = []\n",
    "\n",
    "for class_dir in frame_root_dir.iterdir():\n",
    "    if class_dir.is_dir():\n",
    "        for video_dir in class_dir.iterdir():\n",
    "            if video_dir.is_dir():\n",
    "                for frame_path in video_dir.glob(\"*.jpg\"):\n",
    "                    img = cv2.imread(str(frame_path))\n",
    "                    if img is None or img.size == 0:\n",
    "                        corrupted.append(frame_path)\n",
    "\n",
    "if corrupted:\n",
    "    print(f\" Found {len(corrupted)} corrupted/unreadable frames:\")\n",
    "    for path in corrupted:\n",
    "        print(f\" {path}\")\n",
    "else:\n",
    "    print(\"‚úÖ All frame images are readable and non-empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0972c0",
   "metadata": {},
   "source": [
    "## Detect Frames with Unusual Dimensions\n",
    "\n",
    "This chunk checks if any extracted frame has **unexpectedly small dimensions**, which might indicate:\n",
    "- Cropping issues\n",
    "- Encoding errors\n",
    "- Or videos with very low resolution\n",
    "\n",
    "### What it does:\n",
    "- Iterates through all `.jpg` frames.\n",
    "- Loads each image using OpenCV.\n",
    "- Flags any frame where **height or width is less than 100 pixels**.\n",
    "\n",
    "### Output:\n",
    "- A list of all frames with unusual (too small) dimensions.\n",
    "- A success message if all frames are of acceptable size.\n",
    "\n",
    "> Frames with weird sizes might break my model input pipeline or degrade performance. This check ensures **resolution consistency** across the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2671ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè All frames have normal dimensions.\n"
     ]
    }
   ],
   "source": [
    "weird_dims = []\n",
    "\n",
    "for class_dir in frame_root_dir.iterdir():\n",
    "    if class_dir.is_dir():\n",
    "        for video_dir in class_dir.iterdir():\n",
    "            if video_dir.is_dir():\n",
    "                for frame_path in video_dir.glob(\"*.jpg\"):\n",
    "                    img = cv2.imread(str(frame_path))\n",
    "                    if img is not None:\n",
    "                        h, w = img.shape[:2]\n",
    "                        if h < 100 or w < 100:  \n",
    "                            weird_dims.append((frame_path, (w, h)))\n",
    "\n",
    "if weird_dims:\n",
    "    print(f\"\\nüîç Found {len(weird_dims)} frames with unusual size:\")\n",
    "    for path, dim in weird_dims:\n",
    "        print(f\"{path}: {dim}\")\n",
    "else:\n",
    "    print(\"üìè All frames have normal dimensions.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
