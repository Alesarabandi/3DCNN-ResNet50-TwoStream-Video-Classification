{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3935e948",
   "metadata": {},
   "source": [
    "Aight, right before closing the project, I encounter something interesting in this article - [On the Integration of Optical Flow and Action Recognition (GCPR 2018)](https://www.cvlibs.net/publications/Sevilla-Lara2018GCPR.pdf), and found i quiet fascinating, so I decided to do it, but a big question pops up in my mind; ***if I already fed 16 consecutive frames to my model to detect motion, why do I even need to do so?*** tune in for the answer at the end of this phase (by end phase i mean file '7.TwoStreams.ipynb' cuz this file is only for flow extraction)\n",
    "\n",
    "### What is Optical Flow?\n",
    "\n",
    "**Optical flow** is the pattern of apparent motion of objects between two consecutive frames in a video, caused by the movement of objects or the camera itself. It's a dense, pixel-wise motion field that estimates where each pixel in the first frame has moved to in the second.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Extract Optical Flow?\n",
    "\n",
    "Optical flow captures **temporal information**‚Äîwhat's changing over time, not just what's present in a single frame. This is crucial in:\n",
    "\n",
    "* **Action recognition** (like your HMDB51 project): humans move, and we care about *how* they move.\n",
    "* **Video understanding**: even a still person blinking or shifting can matter.\n",
    "* **Scene dynamics**: camera pans, zooms, or object tracking all rely on motion cues.\n",
    "\n",
    "Without optical flow, a model sees only *what* is in a scene. With flow, it sees *what‚Äôs happening*.\n",
    "\n",
    "---\n",
    "\n",
    "### X-flow and Y-flow ‚Äî What Do They Show?\n",
    "\n",
    "Once you compute optical flow, the result is usually split into **two components**:\n",
    "\n",
    "* **x\\_flow**  ‚Äî the **horizontal displacement** of pixels between two frames (left ‚Üî right).\n",
    "* **y\\_flow**  ‚Äî the **vertical displacement** (up ‚Üï down).\n",
    "\n",
    "Imagine tracking a single pixel: If it moves 5 pixels to the right and 2 pixels up from one frame to the next, you'd have:\n",
    "$x\\_flow = +5, y\\_flow = -2$\n",
    "\n",
    "These values are usually stored as **grayscale images** where pixel intensity represents motion magnitude and direction.\n",
    "\n",
    "---\n",
    "\n",
    "### Optical Flow\n",
    "\n",
    "At the heart of optical flow estimation is the **brightness constancy assumption**, which says:\n",
    "\n",
    "$I(x,y,t) = I(x+\\Delta x, y+\\Delta y, t+\\Delta t)$\n",
    "\n",
    "This means a pixel‚Äôs brightness doesn't change as it moves; only its position does.\n",
    "Using a Taylor expansion and dropping higher-order terms, we get the **optical flow constraint equation**:\n",
    "\n",
    "$I_x \\cdot v_x + I_y \\cdot v_y + I_t = 0$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $I_x$ and $I_y$ are the spatial gradients of the image\n",
    "* $I_t$ is the temporal gradient (change over time)\n",
    "* $v_x$ and $v_y$ are the optical flow components (what we're solving for)\n",
    "\n",
    "In practice, algorithms like **Farneback**, **TV-L1**, or **Lucas-Kanade** are used to solve this under determined system by applying extra constraints. But I used Farneback.\n",
    "\n",
    "### Why I Used Farneback Instead of TV-L1 for Optical Flow Extraction\n",
    "\n",
    "In this project, I‚Äôve opted to use the **Farneback method** to compute dense optical flow instead of the more accurate **TV-L1 algorithm** ‚Äî and here‚Äôs why;\n",
    "\n",
    "While **TV-L1** is known for producing high-quality, noise-resistant motion fields that are great for action recognition, it's also **computationally very expensive**. I ran a test and estimated that extracting flow for the entire HMDB51 dataset using TV-L1 would take over **86 hours** (you can see in the screen shot below) on my current setup ‚Äî which simply isn‚Äôt practical for me right now. I‚Äôm not working with a high-end workstation or cluster, so resource constraints are a very real factor.\n",
    "\n",
    "<img src=\"/Users/alesarabandi/Downloads/DEEPLEARING/project/Screenshot 2025-06-17 at 18.04.22.png\" width=\"600\">\n",
    "\n",
    "Instead, I went with the **Farneback method**, which is **significantly faster** and allows me to complete the extraction in a reasonable amount of time, while still capturing the essential motion cues needed for comparing models.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä TV-L1 vs. Farneback ‚Äî Comparison\n",
    "\n",
    "| Feature              | TV-L1                           | Farneback                        |\n",
    "|----------------------|----------------------------------|----------------------------------|\n",
    "| Speed             | Very slow (hours/days)          | Fast (minutes/hours)            |\n",
    "| Accuracy          | High (better for subtle motion) | Medium (less robust to noise)   |\n",
    "| Compute Required  | High          | Low           |\n",
    "| Output Quality    | Sharper, sparse-friendly flows  | Smoother, denser flows          |\n",
    "| Use Case Fit      | Production / research-grade     | Prototyping / resource-limited  |\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c5e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224bb9f8",
   "metadata": {},
   "source": [
    "### Looping through my dataset structure\n",
    "\n",
    "In this bit, I'm walking through my dataset directory to collect **all video paths**, organised like this:  \n",
    "`class_name/video_name`.\n",
    "\n",
    "- I start with the top-level `frames` directory, where each subfolder is a different **action class**.\n",
    "- Then I dig into each class folder to find the individual **video subfolders**.\n",
    "- For each proper folder (not random files), I build a relative path like `brush_hair/video_001` and chuck it into my `all_videos` list.\n",
    "\n",
    "Basically, I'm indexing my whole dataset so I can process the videos later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dir = \"/Users/alesarabandi/Downloads/DEEPLEARING/frames\"  \n",
    "\n",
    "all_videos = []\n",
    "\n",
    "for class_name in sorted(os.listdir(frames_dir)):\n",
    "    class_path = os.path.join(frames_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue  # Skip non-folder files\n",
    "    for video_name in sorted(os.listdir(class_path)):\n",
    "        video_path = os.path.join(class_path, video_name)\n",
    "        if os.path.isdir(video_path):\n",
    "            rel_path = os.path.join(class_name, video_name)\n",
    "            all_videos.append(rel_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6792c08b",
   "metadata": {},
   "source": [
    "### Extracting Optical Flow (Farneback style)\n",
    "\n",
    "So here, I‚Äôm loading video frames and computing **Farneback optical flow** between consecutive frames ‚Äî basically tracking motion across each clip. üé•‚û°Ô∏èüé•\n",
    "\n",
    "#### What‚Äôs going on?\n",
    "\n",
    "- First, I load all `.jpg` frames from a folder (thanks to `load_frames_from_folder`).\n",
    "- Then, in `compute_and_save_farneback_flow`, I:\n",
    "  - Read in all frame paths and make sure there‚Äôs at least 2 frames to work with.\n",
    "  - Create a matching output folder for saving the flow results.\n",
    "  - Loop over each frame pair (previous ‚Üí current) and calculate motion using **Farneback‚Äôs method**.\n",
    "  - I clip the flow to stay within `[-20, 20]` using the `bound` parameter ‚Äî keeps things tidy and avoids weird spikes.\n",
    "  - Then, I normalise the flow to `[0, 255]` for saving as image files.\n",
    "\n",
    "#### What are `flow_x` and `flow_y`?\n",
    "\n",
    "- `flow_x`: shows **horizontal** motion between frames (left ‚Üî right).\n",
    "- `flow_y`: shows **vertical** motion (up ‚Üï down).\n",
    "\n",
    "These are saved as separate greyscale images (`flow_x_0001.jpg`, `flow_y_0001.jpg`, etc.) so I can feed them into a model later.\n",
    "\n",
    "#### The (basic) maths behind it\n",
    "\n",
    "Optical flow estimates the displacement vector $\\vec{d} = (u, v)$ at each pixel, assuming brightness constancy:\n",
    "\n",
    "$$\n",
    "I(x, y, t) \\approx I(x + u, y + v, t + 1)\n",
    "$$\n",
    "\n",
    "\n",
    "Farneback‚Äôs method builds a polynomial expansion of the image signal in local windows, then computes flow from the deformation between those polynomials. It‚Äôs fast but not perfect.\n",
    "\n",
    "All in all, this is a speed-friendly alternative to TV-L1 ‚Äî not as precise, but waaay faster.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ba59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def load_frames_from_folder(folder):\n",
    "    \"\"\"Loads all .jpg frames from a folder, sorted by filename.\"\"\"\n",
    "    frames = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            frame = cv2.imread(os.path.join(folder, filename))\n",
    "            if frame is not None:\n",
    "                frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def compute_and_save_farneback_flow(video_folder, output_root, bound=20):\n",
    "    frame_paths = sorted(glob(os.path.join(video_folder, '*.jpg')))\n",
    "    if len(frame_paths) < 2:\n",
    "        print(f\"Skipped: Not enough frames in {video_folder}\")\n",
    "        return\n",
    "\n",
    "    output_folder = video_folder.replace('/frames/frames', output_root)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    prev = cv2.imread(frame_paths[0])\n",
    "    prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    for i in range(1, len(frame_paths)):\n",
    "        curr = cv2.imread(frame_paths[i])\n",
    "        curr_gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            prev_gray, curr_gray,\n",
    "            None,\n",
    "            pyr_scale=0.5, levels=3, winsize=15,\n",
    "            iterations=3, poly_n=5, poly_sigma=1.2,\n",
    "            flags=0\n",
    "        )\n",
    "\n",
    "        # Clip and normalise\n",
    "        flow = np.clip(flow, -bound, bound)\n",
    "        flow = ((flow + bound) * (255.0 / (2 * bound))).astype(np.uint8)\n",
    "\n",
    "        # Split and save x and y\n",
    "        flow_x, flow_y = flow[..., 0], flow[..., 1]\n",
    "        cv2.imwrite(os.path.join(output_folder, f'flow_x_{i:04d}.jpg'), flow_x)\n",
    "        cv2.imwrite(os.path.join(output_folder, f'flow_y_{i:04d}.jpg'), flow_y)\n",
    "\n",
    "        prev_gray = curr_gray\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff5aee",
   "metadata": {},
   "source": [
    "### Kicking Off the Flow Extraction\n",
    "\n",
    "this is where I actually **run the Farneback optical flow** extraction across my whole dataset. Let‚Äôs break it down:\n",
    "\n",
    "\n",
    "- My `frames_dir` points to the root folder where each **class** has its own folder, and inside that are folders for each **video**.\n",
    "- I define `output_root` for where I‚Äôll save all the computed flow images.\n",
    "\n",
    "#### Next:\n",
    "\n",
    "- I grab all video directories using `glob` ‚Äî so paths look like:  \n",
    "  `frames_dir/class_name/video_name/*.jpg`.\n",
    "- I then loop through every video folder using `tqdm` to get a progress bar.\n",
    "\n",
    "For every folder:\n",
    "- I run `compute_and_save_farneback_flow()` to generate optical flow.\n",
    "- If anything breaks (e.g., weird folders, missing files), I catch the error and print a message so it doesn‚Äôt crash the whole loop.\n",
    "\n",
    "This script just **batch processes** my entire dataset, one video at a time, and builds the `flow_x` and `flow_y` images for each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0480347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6766 videos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Farneback Flow:   0%|          | 24/6766 [00:08<34:48,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_fr_goo_0\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_le_goo_1\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_le_goo_2\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_le_goo_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Farneback Flow:  23%|‚ñà‚ñà‚ñé       | 1574/6766 [09:03<34:25,  2.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_f_cm_np2_le_goo_0\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_u_cm_np2_ba_goo_1\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_u_cm_np2_fr_goo_2\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_u_cm_np2_fr_goo_3\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_f_cm_np2_le_goo_0\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_u_cm_np2_ba_goo_1\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_u_cm_np2_fr_goo_2\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_u_cm_np2_fr_goo_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Farneback Flow:  25%|‚ñà‚ñà‚ñç       | 1691/6766 [09:44<28:19,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/flic_flac/BHS___FlickFlack_[Tutorial]_flic_flac_f_cm_np1_le_med_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Farneback Flow:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 4660/6766 [24:48<09:36,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/situp/Ab_Workout__(_6_pack_abs_)_[_ab_exercises_for_ripped_abs_]_situp_f_nm_np1_le_goo_0\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/situp/Ab_Workout__(_6_pack_abs_)_[_ab_exercises_for_ripped_abs_]_situp_f_nm_np1_le_goo_1\n",
      "Skipped: Not enough frames in /Users/alesarabandi/Downloads/DEEPLEARING/frames/situp/Ab_Workout__(_6_pack_abs_)_[_ab_exercises_for_ripped_abs_]_situp_f_nm_np1_le_goo_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Farneback Flow: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6766/6766 [36:30<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "frames_dir = \"/Users/alesarabandi/Downloads/DEEPLEARING/frames\"  \n",
    "output_root = \"/Users/alesarabandi/Downloads/DEEPLEARING\"\n",
    "\n",
    "# Each video is under: frames_dir/class_name/video_name/*.jpg\n",
    "video_dirs = sorted(glob(os.path.join(frames_dir, '*', '*')))  # class/video\n",
    "\n",
    "print(f\"Found {len(video_dirs)} videos.\")\n",
    "\n",
    "for video_folder in tqdm(video_dirs, desc=\"Computing Farneback Flow\"):\n",
    "    try:\n",
    "        compute_and_save_farneback_flow(video_folder, output_root)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {video_folder}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3eabaa",
   "metadata": {},
   "source": [
    "### Tidying Up the Flow Files\n",
    "\n",
    "So after generating all the optical flow images, things got a bit messy in my dataset ‚Äî flow files (`flow_x_*.jpg`, `flow_y_*.jpg`) were scattered right inside each video folder.\n",
    "\n",
    "#### What I‚Äôm doing here:\n",
    "\n",
    "- I loop through each class folder inside my `frames_root`.\n",
    "- Then for each video folder within that class, I:\n",
    "  1. Create a subfolder called `flows` .\n",
    "  2. Move all the `flow_x_*.jpg` and `flow_y_*.jpg` files into that `flows` folder using `shutil.move()` .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd84b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organising flows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52/52 [01:05<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "frames_root = \"/Users/alesarabandi/Downloads/DEEPLEARING/frames\"  # my current mixed folder root\n",
    "\n",
    "for class_name in tqdm(os.listdir(frames_root), desc=\"Organising flows\"):\n",
    "    class_path = os.path.join(frames_root, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    for video_name in os.listdir(class_path):\n",
    "        video_path = os.path.join(class_path, video_name)\n",
    "        if not os.path.isdir(video_path):\n",
    "            continue\n",
    "\n",
    "        # Create 'flows' subfolder inside each video folder\n",
    "        flows_path = os.path.join(video_path, \"flows\")\n",
    "        os.makedirs(flows_path, exist_ok=True)\n",
    "\n",
    "        # Move flow images into the 'flows' folder\n",
    "        for fname in os.listdir(video_path):\n",
    "            if fname.startswith(\"flow_x_\") or fname.startswith(\"flow_y_\"):\n",
    "                src = os.path.join(video_path, fname)\n",
    "                dst = os.path.join(flows_path, fname)\n",
    "                shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985137c",
   "metadata": {},
   "source": [
    "### Removing Broken or Corrupted Video Folders\n",
    "\n",
    "Some of the videos in my dataset were totally unusable ‚Äî either missing frames, broken audio, or just a mess. So, I made a list of known bad apples and deleted them manually to keep my dataset clean and consistent. It is not a big deal, they're just 16 videos from 7k, so I prefer to delete them just to prevent this small issue transform to an avalanche later. \n",
    "\n",
    "#### What‚Äôs happening:\n",
    "\n",
    "- I defined a list of **relative paths** to dodgy video folders that I want gone. \n",
    "- Then, for each one:\n",
    "  - I build its **absolute path** from my `frames` root.\n",
    "  - If the folder exists, I nuke it with `shutil.rmtree()`.\n",
    "  - Otherwise, I just log that it‚Äôs already gone ‚Äî no fuss.\n",
    "\n",
    "This is essential for preventing crashes during training or flow extraction later down the line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_fr_goo_0\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_le_goo_1\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_le_goo_2\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_le_goo_3\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_f_cm_np2_le_goo_0\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_u_cm_np2_ba_goo_1\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_u_cm_np2_fr_goo_2\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_u_cm_np2_fr_goo_3\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_f_cm_np2_le_goo_0\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_u_cm_np2_ba_goo_1\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_u_cm_np2_fr_goo_2\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_u_cm_np2_fr_goo_3\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/flic_flac/BHS___FlickFlack_[Tutorial]_flic_flac_f_cm_np1_le_med_0\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/situp/Ab_Workout__(_6_pack_abs_)_[_ab_exercises_for_ripped_abs_]_situp_f_nm_np1_le_goo_0\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/situp/Ab_Workout__(_6_pack_abs_)_[_ab_exercises_for_ripped_abs_]_situp_f_nm_np1_le_goo_1\n",
      "‚úÖ Deleted: /Users/alesarabandi/Downloads/DEEPLEARING/frames/situp/Ab_Workout__(_6_pack_abs_)_[_ab_exercises_for_ripped_abs_]_situp_f_nm_np1_le_goo_2\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "#  root path\n",
    "fr_root = \"/Users/alesarabandi/Downloads/DEEPLEARING/frames\"\n",
    "\n",
    "# Relative paths from the correct root\n",
    "relative_paths_to_delete = [\n",
    "    \"brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_fr_goo_0\",\n",
    "    \"brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_le_goo_1\",\n",
    "    \"brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_le_goo_2\",\n",
    "    \"brush_hair/Brushing_Her_Hair__[_NEW_AUDIO_]_UPDATED!!!!_brush_hair_h_cm_np1_le_goo_3\",\n",
    "    \"fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_f_cm_np2_le_goo_0\",\n",
    "    \"fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_u_cm_np2_ba_goo_1\",\n",
    "    \"fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_u_cm_np2_fr_goo_2\",\n",
    "    \"fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_avi_fencing_u_cm_np2_fr_goo_3\",\n",
    "    \"fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_f_cm_np2_le_goo_0\",\n",
    "    \"fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_u_cm_np2_ba_goo_1\",\n",
    "    \"fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_u_cm_np2_fr_goo_2\",\n",
    "    \"fencing/Die_Another_Day_-_Fencing_Scene_Part_1_[HD]_fencing_u_cm_np2_fr_goo_3\",\n",
    "    \"flic_flac/BHS___FlickFlack_[Tutorial]_flic_flac_f_cm_np1_le_med_0\",\n",
    "    \"situp/Ab_Workout__(_6_pack_abs_)_[_ab_exercises_for_ripped_abs_]_situp_f_nm_np1_le_goo_0\",\n",
    "    \"situp/Ab_Workout__(_6_pack_abs_)_[_ab_exercises_for_ripped_abs_]_situp_f_nm_np1_le_goo_1\",\n",
    "    \"situp/Ab_Workout__(_6_pack_abs_)_[_ab_exercises_for_ripped_abs_]_situp_f_nm_np1_le_goo_2\"\n",
    "]\n",
    "\n",
    "# Now delete those folders\n",
    "for rel_path in relative_paths_to_delete:\n",
    "    abs_path = os.path.join(fr_root, rel_path)\n",
    "    if os.path.exists(abs_path):\n",
    "        shutil.rmtree(abs_path)\n",
    "        print(f\"‚úÖ Deleted: {abs_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Not found (already gone?): {abs_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
